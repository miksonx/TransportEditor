\chapter{Sequential Transport planning}

In this chapter, we describe the approaches we
selected or designed, implemented, and tested.
We will attempt to leverage the acquired
Transport domain knowledge
in these approaches as much as possible.

\section{State-space forward planning}\label{forward-planning}

One of the most straightforward approaches to planning
is forward search \citep[Section~4.2]{Ghallab2004}
in state space (Figure~\ref{alg:forward-search}).
Although it is defined on a classical representation,
it can be used on any planning problem, where we can
\begin{itemize}
\item determine if a state is a goal state or not;
\item iterate over all actions applicable to a state; and
\item compute a successor state by applying an action to the current state.
\end{itemize}
The algorithm, despite its simplicity, is one of the most frequently
used in domain-independent planners.
There are two key steps of the algorithm, which
cause the most problems in practice: representing
the applicable actions (step 6) and choosing the
next action to apply (step 8).

\myalg{Forward Search}%
{%
\Input a planning problem in a classical representation $\mathcal{P} = (S, O, \gamma, s_0, g)$
\Output a plan $\pi$
\Function{Forward-Search}{$\mathcal{P}$}
\State $s \gets s_0$ 
\State $\pi \gets $ empty plan
\Loop
\If {$s$ satisfies $g$} \Return $\pi$ \EndIf
\State $A_s \gets \{a \,|\, o \in O$, $a$ is a ground instance of $o \;\&\; \mt{precond}(a) \mt{ is true in } s\}$
\If {$A_s = \emptyset$} \Return failure \EndIf
\State (nondeterministical) choose an action $a \in A_s$
\State $s \gets \gamma(s, a)$
\State $\pi \gets$ append $a$ to $\pi$
\EndLoop
\EndFunction
}%
{A forward search planning algorithm.}{A forward search planning algorithm for Transport. Adapted from \citet[Figure~4.1]{Ghallab2004}.}{forward-search}{bt}

Representing state transitions in step 6
is a technical problem of representing successor states
in state space search \citep[Section~3.2]{Russell1995}.
Due to limited memory,
applicable actions are grounded from operators
on demand, as are the corresponding successor states
\citep[Section~3.4]{Russell1995}.

The forward search algorithm in its specified form is nondeterministic.
If we knew which action to choose in step 8,
we would know how to solve the planning problem.
Since we generally do not know which action (state transition) to chose in a given state, the choice is usually delegated to a suitable
search algorithm, which makes the algorithm deterministic.


\subsection{Deterministic search algorithms}

State space search algorithms are a heavily studied area
of computer science, and any reasonable search algorithm applied
to forward search will yield correct results.
Example of such a algorithms are Breadth-First Search (BFS), 
Depth-First Search, and many more \citep[Section~3.5]{Russell1995}.
The choice of a search algorithm greatly influence
the quality of resulting plans when applied to forward search.

As the sizes of planning problems grow,
choosing a search algorithm is even more crucial ---
several well performing algorithms on small problems (like BFS)
exceed reasonable run times and become unusable for practical applications.
An important and practically useful search algorithm
withstanding larger problem sizes is the \textit{A* algorithm} (Figure~\ref{alg:astar})
introduced in \citet{Hart1968}.

\myalg{Forward Search with A*}%
{%
\Input a planning problem in a classical representation $\mathcal{P} = (S, O, \gamma, s_0, g)$,
an (admissible and monotone) heuristic function $h$
\Output a plan $\pi$
\Function{Collect-Plan}{$s, \pi$}
\State $\pi_s \gets $ empty list
\While{$s \neq \emptyset$}
	\State $(s', a) \gets \pi[s]$
	\State $\pi_s \gets$ prepend $a$ to $\pi_s$
	\State $s \gets s'$
\EndWhile
\State \Return $\pi_s$
\EndFunction

\Function{Forward-Search-Astar}{$\mathcal{P}$}
\State $\pi \gets $ empty map, $f[*] \gets \infty$, $g[*] \gets \infty$, $o \gets \{s_0\}$, $c \gets \emptyset$
\State $\pi[s_0] \gets \emptyset$, 
$g[s_0] \gets 0$, $f[s_0] \gets h(s_0)$
\While{$o \neq \emptyset$}
\State $s \gets \min_{s \in o} f[s]$, $o \gets o \setminus \{s\}$, $c \gets c \cup \{s\}$
\If {$s$ satisfies $g$} \Return \Call{Collect-Plan}{$s$, $\pi$} \EndIf
\ForAll{actions $a \in$ \Call{Generate-Actions}{$s, \pi$}}
	\State $s' \gets \gamma(s, a)$
	\If{$s' \notin c$} \Comment{Not visited yet}
		\If{$s' \notin o$} $o \gets o \cup \{s'\}$ \Comment{Discovered a new state} \EndIf 
		\If{$g[s] + \mt{cost}(a) < g[s']$} \Comment{Found a better path}
			\State $\pi[s'] \gets (s, a)$
			\State $g[s'] \gets g[s] + \mt{cost}(a)$
			\State $f[s'] \gets g[s'] + h(s')$
		\EndIf
	\EndIf
\EndFor
\EndWhile
\Return failure
\EndFunction
}%
{Forward search planning using A*.}{Forward search planning using A*.
\textsc{Generate-Actions} is a function that produces actions applicable to the state $s$.}{astar}{tb}

A* has many important properties. We pinpoint one important to us, namely its admissibility.
A search algorithm is \textit{admissible}
if it is guaranteed to find an optimal path from a state $s$
to a goal state $s_g$ for any state space \citep{Hart1968}.
A* is admissible and optimal given an admissible heuristic.

An \textit{admissible} heuristic does not overestimate
the true value it is approximating. During planning in state space,
when examining a state $s$, we want to estimate the total costs of the best
plan getting us to a goal state from state $s$. In other words, because we are
trying to minimize the total cost,
a planning heuristic $h: S \to \N_0$ is admissible if and only if $\forall s \in S : h(s) \leq h^*(s),$
where $h^*$ is the true total cost (in other words, the optimal heuristic). A similar definition is applicable for minimizing duration in the temporal variant.
As mentioned previously, admissible heuristics have more desirable properties when used with search algorithms
--- for example, they guarantee that the first path to a goal state we find
will be the optimal \TODO{admissible + monotone?}.

A slight modification of A*, called \textit{Weighted A*} \citep{Pohl1970},
tends to yield good quality plans in a shorter amount of time,
at the expense of
sacrificing admissibility. The only difference
when compared to A* is that the heuristic $h(x)$
is substituted for $h_w(x) = w \cdot h(x),$
where $w$ is a weight constant. Choosing a weight greater
than 1 makes the heuristic inadmissible,
but guides the search towards a goal state faster.


\subsection{Heuristics for forward search in Transport}\label{seq-heuristics}

When designing a heuristic, we want to provide an estimate
of the total plan cost or duration
that is as precise as possible. This
will help guide the search to a goal state as quickly as
possible.

We will now describe several heuristics for sequential
Transport using the state-variable representation.
In the following, the value of the $\mt{target(p)}$ function represents
the target location of a package $p$ in the set of packages $P$.

\subsubsection{Trivially admissible Transport heuristic}\label{sfa0}

The simplest heuristic (apart from the zero heuristic $h_0 \equiv 0$) that is applicable to all variants of Transport
is one that counts the minimum number of pickup and drop
actions necessary to reach a goal state.
To obtain the correct count, we add 1 for each
package that is not yet at its destination (it will need to be dropped there) and another 1 for each package
that is additionally not in a vehicle (it will need to be picked up):

$$h'_{0}(s) = \sum_{\substack{
p \in P\\ \mt{at}(p) \neq \mt{target}(p)}} 1
+ \sum_{\substack{
p \in P\\ \mt{at}(p) \neq \mt{target}(p)\\
\mt{at}(p) \neq \mt{nil}}} 1.$$

This $h'_0$ is admissible, but it is practically unusable, as it
very poorly approximates 
the cost of the optimal remaining actions to a goal state
--- recall that costs of \drive{} actions are generally much higher than the costs of \pickup{} and \drop{} actions.

\subsubsection{Package distance heuristic}\label{sfa1}

In \texttt{transport-strips}, the only thing we want is to deliver packages to their destinations. Therefore, a straightforward heuristic is one that calculates the length of a shortest
path of each package to its destination and sums the lengths for all packages.
To make the heuristic more precise, we can add the
value of $h'_0$ to it, as the \pickup{} and \drop{}
actions also have to occur in the optimal plan:
$$h_1 = h'_0 + \sum_{p \in P} \mt{spd}(location(p), target(p)),$$
where the $location: P \to L$ function,
with values in the set of all locations $L$, is defined as
$$location(p) = \begin{cases} 
   \mt{at}(p) & \text{if } \mt{at}(p) \neq \mt{nil}\\
   \mt{at}(\mt{in}(p)) & \text{else}.
  \end{cases}$$
The location of a package will is, therefore, defined
as the location it is at, or, if it is in a vehicle,
the location of the vehicle.
The function $\mt{spd}: L \times L \to \N_0$ represents
the shortest path distance between the two locations.

This heuristic is definitely not optimal, meaning that there are states,
where we will need to add actions to reach a goal state with a higher total cost than the value of the heuristic in that state.

However, it is important to note, the heuristic
is not even admissible, so its value might sometimes overestimate the total cost needed.
To see why, let us have a network with just two locations $A$ and $B$.
A vehicle of capacity 2 and two packages are located at $A$ and both packages want to be
transported to $B$. The road between $A$ and $B$ is symmetric and has length
of a 100. It is trivial to see that the optimal plan consists of two \pickup{} actions,
followed by a \drive{} and two \drop{} actions. This plan has a total cost of $2+100+2=104$,
but the heuristic would estimate that we need actions
that cost $204$.

\subsubsection{Minimum Spanning Tree heuristic}\label{sfa2}

\TODO{mst approach}
\citet{Kruskal1956}

\subsubsection{Package and vehicle distance heuristic}\label{sfa3}

As an extension of the package distance heuristic,
we will also add the distance of the nearest vehicle for
each package:
$$h_3 = h_1 + \sum_{p \in P} \min_{v \in V} \mt{spd}(location(p), \mt{at}(v)),$$
where $V$ is the set of all vehicles.
As follows from the inadmissibility of $h_1$, $h_3$
is also inadmissible and nonoptimal.

\subsubsection{Package or vehicle distance heuristic}\label{sfa4}

A variation on the package and distance heuristic
is one that does not sum, but instead takes
the minimum distances.
Specifically, for each package, the minimum
is taken from the distance to its target location,
distance to the nearest vehicle,
and the distance to the nearest package:
\begin{align*}
h_4 = \sum_{p \in P} \min\lbrace
&\mt{spd}(location(p), target(p)),
\min_{v \in V} \mt{spd}(location(p), \mt{at}(v)),\\
&\min_{p' \in P} \mt{spd}(location(p), location(p'))\rbrace.
\end{align*}
\TODO{Admissibility}


\subsubsection{Discussion}

\TODO{discuss the advantages/usability}








\subsection{Sequential Forward A*}\label{sfa}

\textit{Sequential Forward A*} (SFA) is a planner for sequential Transport based on forward search using A* (Figure~\ref{alg:astar}).
It utilizes most of the domain knowledge described
in Section~\ref{domain-info} and~\ref{datasets}
to prune the search space as much as possible
without sacrificing admissibility.

However, the domain knowledge alone does not
prune away enough search space to
generate plans in an efficient way.
With the addition of (admissible and nonadmissible)
heuristics
from Section~\ref{seq-heuristics}
implementations of the planner become reasonably useful
on practical problems, as will be demonstrated
later during experimental evaluation.

A variant of SFA, 
\textit{Weighted Sequential Forward A*} (WSFA)
swaps A* search for Weighted A* in the SFA planner.

\subsection{Meta-heuristically weighted SFA*}\label{msfa}

\textit{Meta-heuristically weighted SFA*} (MSFA) is
a meta-planner built on top of a WSFA planner with
a given heuristic.

Given two hyperparameters $\alpha \in [0, 1]$ and $w_0 \in [1, \infty)$,
it runs the WSFA planner with the weight $w \gets w_0$,
waits for the planner to find a plan,
and then (exponentially) decays the 
weight of the heuristic function: $w \gets \max(1, \floor*{\alpha \cdot w}).$
Do note that this entails a change of values in the $f$ map
of forward search with A*.
























\section{Ad-hoc planning}\label{ad-hoc}

\subsection{Randomized Restart Planning}\label{rand-restart}

\subsubsection{Randomized Restart From Location Planner}\label{rrfl}

\subsubsection{Randomized Restart On Path Planner}\label{rrop}

\subsubsection{Randomized Restart On Path Nearby Planner}\label{rropn}

\subsubsection{Randomized Restart Around Path Nearby Planner}\label{rrapn}

\subsubsection{Randomized Backtrack Restart Around Path Nearby Planner}\label{rbrapn}

\subsubsection{Randomized Restart Around Path Distribution Planner}\label{rrapd}
























\section{TODO: Formulating Transport as a CSP}
\comment{
\section{Formulating Transport as a CSP}\label{csp-approach}

When discussing related works, we mentioned the Vehicle Routing Problem (Section~\ref{vrp}) and its straightforward
formulation as a Constraint Satisfaction Problem. Utilizing CSPs has been useful
for planning in the past \citep[Section~8.7]{Ghallab2004}
and we will attempt to use domain-specific knowledge to improve upon the standard, domain-independent
formulation.

\subsection{Na{\"{i}}ve CSP formulation}

We will now formulate a sequential Transport (Section~\ref{transport-strips}) problem as a CSP (Section~\ref{csp}) using the na{\"{i}}ve encoding provided in \citet[Section~8.3]{Ghallab2004}.


\TODO{explain the model + constraints}


However, using that strategy, our problems ``blow up'' in size --- as is expected due
to the different complexities of planning versus solving CSPs \citep[Section~8.3.2]{Ghallab2004}. To visualize the difference in our case, we have constructed a state space estimation table (Table~\ref{tab:csp-trivial}) for conversions of two sample sequential Transport problems.

\TODO{recalculate + verify numbers}

\begin{table}[tb]
\begin{center}
\begin{tabular}{l||rr}
\textbf{Features / estimates} & \textbf{p01} & \textbf{p20} \\ 
\midrule
\midrule
\textbf{Best known plan length} & 6 & 351 \\ 
\textbf{Vehicles} & 2 & 4 \\ 
\textbf{Vehicle variables} & 14 & 1 408 \\ 
\textbf{Packages} & 2 & 20 \\ 
\textbf{Package variables} & 14 & 7 040 \\ 
\textbf{Locations} & 5 & 60 \\ 
\textbf{Roads} & 12 & 256 \\
\textbf{Max capacity} & 4 & 4 \\ 
\midrule
\textbf{Ground Drive actions} & 168 & 360 448 \\ 
\textbf{Ground PickUp actions} & 140 & 1 689 600 \\ 
\textbf{Ground Drop actions} & 140 & 1 689 600 \\ 
\midrule
\textbf{Planning variables total} & 48 & 10 207 \\ 
\textbf{Grounded actions total} & 448 & 1 189 838 848 \\ 
\textbf{Search Space Estimate} & $\approx 1.1 \cdot 10^{52}$ & $\approx 1.4 \cdot 10^{27 952}$ \\ % https://www.wolframalpha.com/input/?i=(245120%5E351)+*+4%5E1408+*+60%5E1408+*+1468%5E7040
\end{tabular}
\end{center}
\caption[Search space approximations for a na{\"{i}}ve CSP encoding.]{CSP Search space approximations for the \textit{p01} and \textit{p20} problems from the \textit{seq-sat} track of IPC 2008, using the general and domain-independent encoding from \citet[Section~8.3]{Ghallab2004}.}
\label{tab:csp-trivial}
\end{table}

The first section of the table (rows 1--7) contains problem-specific constants.
The two calculated values in that section, \textit{Vehicle variables} and \textit{Package variables} are the numbers of variables generated for the respective
object by grounding it for every intermediate plan state (before and after applying an action). Therefore, the value is equal to the number of vehicles/packages of the problem
multiplied by the set plan length + 1 (each state corresponds to the state before applying an action + the last state).

In the second section (rows 8--10), we estimate the number of ground actions
Step 1 from \citet[Section~8.3.1]{Ghallab2004} will generate.
We calculate the number of \pickup{} and \drop{} actions the CSP encoding will generate
as $$(\mt{length(plan)} + 1) \cdot \mt{\#vehicles} \cdot \mt{\#locations} \cdot \mt{\#packages},$$
effectively counting all ground planning operators of the problem. Similarly,
the number of \drive{} actions is calculated as
$$(\mt{length(plan)} + 1) \cdot \mt{\#vehicles} \cdot \mt{\#roads},$$
which is more efficient than the na{\"{i}}ve way of
counting all
$$(\mt{length(plan)} + 1) \cdot \mt{\#vehicles} \cdot \mt{\#locations}^2$$
actions.

As we can see from the third section of the table, the number of variables
(planning variables and ground actions) is not extremely high
--- the problem is that the variables have very large domains,
which makes the CSP problem exponentially larger \citep[Section~8.3.2]{Ghallab2004}.
We calculated the \textit{Search Space Size Estimate} (SSE) as
\begin{align*}
\mt{SSE} =\; &\mt{\#ground\_actions}^{l-1} & \textit{\footnotesize select ground actions for the plan}\\
&\cdot \mt{\#capacities}^{l \cdot \mt{\#vehicles}} & \textit{\footnotesize select capacities for vehicle variables}\\
&\cdot \mt{\#locations}^{l \cdot \mt{\#vehicles}} & \textit{\footnotesize select locations for vehicle variables}\\
&\cdot (\mt{\#locations} + \mt{\#vehicles})^{l \cdot \mt{\#pkg}}, & \textit{\footnotesize select locations/vehicles for package variables}
\end{align*}
where we set $l := \mt{length(plan) + 1}$.
For comparison to the SSEs in the last table row, 
the estimated number of atoms in the universe is generally estimated to be about $4 \cdot 10^{80}$.

\subsection{Domain-dependent CSP representation}\label{csp-custom-repr}

We will now devise a different CSP representation for sequential Transport.
While not improving upon the search space estimates of the na{\"{i}}ve formulation
in a theoretical sense, we will describe a slightly more complex
and less general
CSP model that enables us to explore fewer states.

Using OptaPlanner and its shadow variable concept \citep[Section~4.3.6]{DeSmet2017}, we will model our Transport problem without keeping explicit track of capacities,
vehicle and package locations, and ground actions, all of which will be implicitly managed by OptaPlanner, or inferred in the case of capacity and actions.
This means we will reduce the memory overhead, maintaining the same expressive power
and hopefully not enlarge the processing time too much.

\TODO{Describe the specific representation after it is polished in the code}

\TODO{recalculate + verify numbers}

\begin{table}[tb]
\begin{center}
\begin{tabular}{l||rr}
\textbf{Features / estimates} & \textbf{p01} & \textbf{p20} \\ 
\midrule
\midrule
\textbf{Best known plan length} & 6 & 351 \\ 
\textbf{Vehicles} & 2 & 4 \\ 
\textbf{Vehicle shadow vars} & 14 & 1 408 \\
\textbf{Packages} & 2 & 20 \\ 
\textbf{Package shadow vars} & 14 & 7 040 \\
\textbf{Locations} & 5 & 60 \\
\textbf{Roads} & 12 & 256 \\
\textbf{Max capacity} & 4 & 4 \\ 
\midrule
\textbf{Ground Drive actions} & 24 & 1024 \\ 
\textbf{Ground PickUp actions} & 20 & 4800 \\ 
\textbf{Ground Drop actions} & 20 & 4800 \\ 
\midrule
\textbf{Planning variables total} & 48 & 10 207 \\ 
\textbf{Grounded actions in step} & 64 & 10 624 \\ 
\textbf{Action type orderings} & 2 187 & $\approx 8.8 \cdot 10^{167}$ \\ 
\textbf{Search Space Estimate} & $\approx 1.5 \cdot 10^{14}$ & $\approx 2.0 \cdot 10^{637}$ \\
\end{tabular}
\end{center}
\caption[Search space approximations for a domain-dependent CSP representation.]{CSP Search space approximations for the \textit{p01} and \textit{p20} problems from the \textit{seq-sat} track of IPC 2008, using a custom domain-dependent CSP representation for Transport sequential.}
\label{tab:csp-custom}
\end{table}

Using the domain-dependent representation specified, we are now able to construct
a search space estimate table for the same Transport problems (Table~\ref{tab:csp-custom}). 
Do note, that this table cannot be compared directly to the previous one,
because it hides the shadow variable management overhead.
Also, while the table rows look similar, sections 2 and 3 are calculated
differently. The ground action counts in section 2 are not multiplied by $\mt{length(plan)} + 1$
as done previously, because we only represent them once, not at every plan state.
The total number of grounded actions is the same, but they are not explicitly represented as variables. The Search Space size Estimate is therefore calculated differently:
\begin{align*}
\mt{SSE} =\; &3^{\mt{length(plan)} + 1} & \textit{\footnotesize select the action type of each action}\\
&\cdot \mt{\#ground\_actions}^{l-1}. & \textit{\footnotesize select the specific ground action}
\end{align*}
For comparison to the na{\"{i}}ve encoding SSEs which going from the p01 problem to p20 grow by a logarithmic factor of approximately $538$,
whereas the domain-dependent ones only grow by approximately $46$,
which is a huge improvement.

Given the search space reduction, we will now attempt to use this representation
for constructing a CSP-based planner.

\subsection{CSP-based planner}\label{csp-planner}

\TODO{try to run a CSP in OptaPlanner to solve this and compare results, using Section~\ref{csp-custom-repr}}

\TODO{Advantages and shortcommings of a CSP-based planner}

}





















\section{Further approaches}

\TODO{more possible approaches}

