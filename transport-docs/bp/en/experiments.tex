\chapter{Experimental evaluation}

\TODO{Intro: goals + what will we examine and why}

\section{Methodology}

\TODO{Compare with IPC competition results -- mention the rules}

\TODO{compare runtimes, scores, define the quality}
\TODO{deduplicate with chapter transport-analysis}

\subsection{Datasets}

\TODO{Where did we get data (reference to transport-analysis datasets section),
where are they attached}

\TODO{define the planners we are comparing with (cite competition proceedings)}

\subsection{Running the experiments}

\TODO{How do we run it: benchmarker}

\TODO{Deterministic \& reliable: What computer hardware, OS, Java version, TransportEditor version \TEver{} (along with git tag \TEtag{}), library versions (Maven), max memory, cputime}

\section{Sequential Transport}

\subsection{Results}

\section{Original competition results}

\TODO{re-read and refactor after moving here}

In the updated results of the seq-sat track of IPC 2008\footnote{\url{http://icaps-conference.org/ipc2008/deterministic/Results.html}} published after the competition,
the overall winner \textit{lama} (a Fast-Downward \TODO{ref} planner configuration)
was hands-down the best planner on the sequential Transport domain, winning
with a total quality of $28.93/30$, where all other planners had less than $20/30$.
Only 5 problem instances were solved suboptimally by \textit{lama}.
\textit{Quality} is calculated for a given planner and problem $p$
as $$\frac{\mt{total-cost}(\mt{planner}(p))}{\mt{total-cost}(BEST)},$$ where the results called $BEST$
are precalculated outside of the competition environment, or the best result of a planner in the competition, depending on which plan has a lower total cost. The quality is, therefore, a number between $0$ and $1$. The total quality is calculated as the sum of qualities on all problem instances.

As mentioned, we were not able to gather data from the IPC 2011,
hence the results cannot be meaningfully interpreted.
The competition featured 20 sequential Transport problems,
with 4 planners achieving a total quality of more than $15/20$.

In the seq-sat track of IPC 2014, the winner on the Transport domain
was without a doubt the \textit{Mercury} planner, achieving
a stunning $20/20$ total quality. Even more interesting is the fact that
the runner-up \textit{yahsp3-mt} achieved a score of $10.74/20$
and all other planners achieved sub $10/20$ total quality.
The IPC 2014 used different problem instances than the IPC 2008
and we will test our approaches on both datasets.

\TODO{try to analyze why}



\TODO{IPC score tables + runtime charts + attach plans generated}

\subsection{Discussion}

\section{Temporal Transport}

\subsection{Results}

\TODO{intro + re-factor the original compo results}

The temporal variant of Transport was only used in IPC 2008.
Planners that entered that competition did not cope well with the domain
--- only two non-baseline planners were able to produce at least one plan
for any problem. Additionally, only the simple problem (\verb+p01+) was solved
optimally by any planner. The best total quality was only $7.5/30$, achieved by
\textit{sgplan6}. No other domain in the temporal track had a lower best total quality
than Transport, which, assuming reasonably generated problem instances, hints
at Transport being one of the harder domains for domain-independent temporal planners.

\TODO{Gantt charts + IPC score tables + runtime charts + attach plans generated}

\subsection{Discussion}

\section{Overall result conclusion}


