\chapter{Experimental evaluation}\label{experiments}

In this chapter, we will describe and run experiments
that compare our planners from the last two chapters
with state-of-the-art domain-independent planners from the IPC.
We will briefly discuss the acquired results and interpret them.

\section{Methodology}

Using our benchmarking software (described in the attachments), we will now run experiments in an
environment as similar to the original
IPC as possible, following almost all of the official rules.\puncfootnote{\url{http://icaps-conference.org/ipc2008/deterministic/CompetitionRules.html}}
All planners will be single-threaded and use a maximum of 2GB of memory, with a maximum run time of 30 minutes (planners will
get canceled and prompted for a plan at that time point).
Our planners explicitly and intentionally break the ``domain independence'' rule of the IPC.

The evaluation criteria remain the same:
we focus on plan \textit{quality} in favor of planner run time,
although we will mention runtimes.
The quality of a plan for a specific planner and sequential problem $p$ is defined as
$$\frac{\mt{total-cost}(\mt{planner}(p))}{\mt{total-cost}(BEST)},$$
where the results called $BEST$
are either precalculated outside of the competition environment or they are the best result of one of the planners in the competition, depending on which plan has a lower total cost.
Quality is, therefore, a number between $0$ and $1$.
Note that we will use the original competition's best scores,
which means that the quality of our plans
might sometimes exceed the value of 1
(when our planners find a plan better than all the others found during the competition).
The overall goal for planners is to maximize the sum of qualities over the problem instances in a given dataset, called the \textit{total quality}.
For temporal domains, quality is calculated in the same way, just by substituting total cost
for total time. We sometimes refer to total cost and total time as the \textit{score} of the planner, a term that is not dependent on the domain variant.

We will use four datasets for our experiments --- the seq-sat-6, seq-sat-7,
and seq-sat-8 datasets for sequential
and the tempo-sat-6 for temporal planners (Section~\ref{datasets}).
All the datasets used (and more) are available in the
software project sources (see the attached \nameref{cd-contents}).
Descriptions of planners that we will refer to by their competition names can be found in the respective competition results or booklets for IPC~2008,\puncfootnote{\url{http://icaps-conference.org/ipc2008/deterministic/Planners.html}} IPC~2011 \citep{Garcia-Olaya2011}, and IPC~2014 \citep{Vallati2015}.

In all planners where nondeterminism occurs,
we set the initial random seed to 2017
(on all individual problem runs).
All the following experiments
were run on a computer
containing an 8 core 64-bit processor \texttt{Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz}
with 16 GB of memory, running Gentoo Linux.
A big thank you goes out to the faculty for providing us with access to these machines.
We run all Java programs on Oracle's OpenJDK 
version \texttt{1.8.0\_121}, build \texttt{b13}.
The results presented here were obtained with the \TEver{} version of the TransportEditor project.\puncfootnote{Git tag \TEtag{}, available at \url{https://github.com/oskopek/TransportEditor}} The \texttt{NOTICE.txt} files
in the project module directories specify
the exact versions of libraries used.



















\section{Sequential Transport}

In this section, we present the results of our sequential planners on the seq-sat-6, seq-sat-7, and seq-sat-8 datasets. Specifically, these planners are included in the experiment:
\begin{description}
\item[MSFA3] The meta-heuristically weighted SFA planner (Section~\ref{msfa}) with the package and vehicle distance heuristic (Section~\ref{sfa3})
\item[MSFA5] The meta-heuristically weighted SFA planner with the general marking heuristic (Section~\ref{sfa5})
\item[RRAPN] The Randomized Restart Around Path Nearby planner (Section~\ref{rrapn})
\end{description}

\subsection{Results}\label{sequential-results}

We show an IPC quality table and a quality plot
for the experimental runs on the seq-sat-6 dataset (Figure~\ref{fig:seq-sat-6-results}), seq-sat-7 dataset (Figure~\ref{fig:seq-sat-7-results}), and the seq-sat-8 dataset (Figure~\ref{fig:seq-sat-8-results}). Details about the specific plans along with the benchmark results can be found in the \nameref{cd-contents}.

\begin{figure}[tbp]
\centering
\begin{subtable}{\textwidth}
\centering
\scriptsize
\renewcommand{\footnotesize}{\scriptsize}
\input{../data/seq-sat-6-ipc-scores}
\caption{Quality and score of sequential planners on the seq-sat-6 dataset.}
\label{tab:seq-sat-6-ipc-scores}
\end{subtable}

\vspace{0.5cm}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{../imga/seq-sat-6-quality}
\caption{Quality plot of sequential planners on the seq-sat-6 dataset.}
\label{fig:seq-sat-6-quality}
\end{subfigure}
\caption{Planner results on seq-sat-6.}
\label{fig:seq-sat-6-results}
\end{figure}

\begin{figure}[tbp]
\centering
\begin{subtable}{\textwidth}
\centering
\scriptsize
\renewcommand{\footnotesize}{\scriptsize}
\input{../data/seq-sat-7-ipc-scores}
\caption{Quality and score of sequential planners on the seq-sat-7 dataset.}
\label{tab:seq-sat-7-ipc-scores}
\end{subtable}

\vspace{0.5cm}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{../imga/seq-sat-7-quality}
\caption{Quality plot of sequential planners on the seq-sat-7 dataset.}
\label{fig:seq-sat-7-quality}
\end{subfigure}
\caption{Planner results on seq-sat-7.}
\label{fig:seq-sat-7-results}
\end{figure}

\begin{figure}[tbp]
\centering
\begin{subtable}{\textwidth}
\centering
\scriptsize
\renewcommand{\footnotesize}{\scriptsize}
\input{../data/seq-sat-8-ipc-scores}
\caption{Quality and score of sequential planners on the seq-sat-8 dataset.}
\label{tab:seq-sat-8-ipc-scores}
\end{subtable}

\vspace{0.5cm}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{../imga/seq-sat-8-quality}
\caption{Quality plot of sequential planners on the seq-sat-8 dataset.}
\label{fig:seq-sat-8-quality}
\end{subfigure}
\caption{Planner results on seq-sat-8.}
\label{fig:seq-sat-8-results}
\end{figure}

In the updated results of the sequential satisficing track of IPC 2008\footnote{\url{http://icaps-conference.org/ipc2008/deterministic/Results.html}} published after the competition,
the overall winner LAMA (a Fast Downward based planner)
was hands-down the best planner on the sequential Transport domain, winning
with a total quality of $28.93/30$, where all other planners had less than $20/30$.
Only 5 plans generated by LAMA had a worse total cost than the best known plans. After adding our planners to the results,
the total quality of LAMA drops to $25.38/30$,
because several larger problems were solved better than the
best known solution from IPC 2008.
Our best planner, RRAPN, achieves a total quality of $28.95/30$,
which is a slight improvement over LAMA and other planners. The biggest gain of our planner is in being able to approximate
solutions of larger problems fast, which can be observed on
the results on problems 7--10, 18--20, and 27--30,
which are the largest problems.
On the other hand, RRAPN fails to achieve optimal scores
on smaller problems like \verb+p02+, \verb+p12+, or \verb+p22+,
due to its explicit nature.
\TODO{comment on MSFA3 and MSFA5 once we have the results}

The IPC 2011 featured 20 sequential Transport problems,
with 4 planners (dae\_yahsp, LAMA 2008 and 2011, and roamer) achieving a total quality of more than $15/20$.
Interestingly, LAMA 2008 was able to produce better plans than its 2011 version in 12 out of 20 problems. The overall winner on Transport in 2011, roamer, achieved comparable scores on most problems to both versions of LAMA. The fourth best planner, dae\_yahsp, performed consistenly worse by a small margin, except for two problems, \verb+p04+ and \verb+p05+, where it beat even our planners.
RRAPN consistenly achieves better scores than all the planners in most problems ($17/20$). This can be attributed to the size
of the problems (see Table~\ref{tab:dataset-dimensions}).
\TODO{comment on MSFA3 and MSFA5 once we have the results}

In the satisficing track of IPC 2014, the winner on the Transport domain
was without a doubt the Mercury planner, achieving
a stunning $20/20$ total quality. Even more interesting is the fact that
the runner-up yahsp3-mt achieved a score of only $10.74/20$
and all other planners achieved sub $10/20$ total quality,
accentuating the performance of Mercury even more.
Our planner RRAPN manages to outperform yahsp3-mt with $16.43/20$, yet it fails
to match the results
of Mercury and by a large margin at that.
\TODO{why?}
\TODO{comment on MSFA3 and MSFA5 once we have the results}

















\section{Temporal Transport}

In this section, we present the results of our temporal planners on the tempo-sat-6 dataset. The following planners are included in the experiment:
\begin{description}
\item[RRAPNSched] The scheduled (Section~\ref{sched}) RRAPN planner (Section~\ref{rrapn})
\item[MSFA5Sched] The scheduled MSFA5 planner (Sections~\ref{msfa} and~\ref{sfa5})
\item[RRAPNTemp] The RRAPN Temporal planner (Section~\ref{temporal-approach})
\item[TFD2014] The Temporal Fast Downward planner, version 0.4 from IPC~2014 \citep[Preferring Preferred Operators in Temporal Fast Downward]{Vallati2015}
\end{description}

\subsection{Results}\label{temporal-results}

We show an IPC quality table and a quality plot of an experimental run of these planners on the tempo-sat-6 dataset (Figure~\ref{fig:tempo-sat-6-results}).
Additionally, sample Gantt charts \citep{Gantt1910} of two chosen plans are shown in Figure~\ref{fig:tempo-sat-6-gantt}.
The generated plans and benchmark results can be found in the attached \nameref{cd-contents}.

\begin{figure}[tbp]
\centering
\begin{subtable}{\textwidth}
\centering
\scriptsize
\renewcommand{\footnotesize}{\scriptsize}
\input{../data/tempo-sat-6-ipc-scores}
\caption{Quality and score of sequential planners on the tempo-sat-6 dataset.}
\label{tab:tempo-sat-6-ipc-scores}
\end{subtable}

\vspace{0.5cm}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{../imga/tempo-sat-6-quality}
\caption{Quality plot of sequential planners on the tempo-sat-6 dataset.}
\label{fig:tempo-sat-6-quality}
\end{subfigure}
\caption{Planner results on tempo-sat-6.}
\label{fig:tempo-sat-6-results}
\end{figure}

\begin{figure}[tbp]
\centering
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{../imga/tempo-sat-6-gantt-p15-A}
\caption{Gantt chart of the temporal planner RRAPNSched on the tempo-sat-6 \texttt{p15} problem.}
\label{fig:tempo-sat-6-gantt-15-a}
\end{subfigure}

\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{../imga/tempo-sat-6-gantt-p15-B}
\caption{Gantt chart of the temporal planner TFD2014 on the tempo-sat-6 \texttt{p15} problem.}
\label{fig:tempo-sat-6-gantt-15-b}
\end{subfigure}
\caption{Gantt charts of the temporal planner RRAPNSched and TFD2014 on the tempo-sat-6 \texttt{p15} problem.}
\label{fig:tempo-sat-6-gantt}
\end{figure}

Planners that entered the 2008 temporal track at the IPC did not cope well with the Transport domain
--- only two non-baseline planners (SGPlan$_6$ and TFD) were able to produce at least one plan
for any problem. Additionally, only the smallest problem (\verb+p01+) was solved
to the best known score by any planner.
The best total quality was only $7.5/30$, achieved by
{SGPlan$_6$. No other domain in the temporal track had a lower best total quality
than Transport, which, assuming reasonably generated problem instances, hints
at Transport being one of the harder domains for domain-independent temporal planners.
We observe an evident performance increase of Temporal Fast Downward,
when comparing the qualities of plans of TFD (from 2008) and TFD2014.

Our results further show that using a simple domain-dependent scheduling approach
of sequential plans yields an improvement over domain-independent temporal planners. Our planners RRAPNSched
and RRAPNTemp achieve total qualities of $25.64/30$
and $?/30$, beating even newer temporal planners like TFD2014
by a significant margin.
We see that RRAPNSched produces plans with worse scores than the best known score, mostly on smaller problems. This is mainly due to the fact that plans for smaller problems are easier to precalculate and hence the best known score is closer
to the optimum than the best score estimates for larger problems.

\TODO{solve p10 or comment on why it doesn't work}

\TODO{RRAPNSched a TFD2014, porovnat chyby v Gantt charts}


\section{Overall results}

The attained results show that domain-dependent information can be leveraged
to generate plans of better quality.
We have designed and implemented Transport planners that are able to beat
results from the original competitions in the sequential
and temporal satisficing tracks of the 2008 and 2011 IPCs.
In the 2014 IPC, we would attain second place on overall quality in the Transport domain, behind the $20/20$ result of Mercury.

Another major advantage previously unmentioned is that
our ad-hoc planners generate good solutions quite fast.
Below, we show results from a 1 minute run of RRAPN and RRAPNSched.

\TODO{show results of a 1 minute run}

